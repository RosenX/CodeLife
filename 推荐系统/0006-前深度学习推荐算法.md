# 前深度学习算法

## 协同过滤族

### UserCF

步骤：

1. 生成user-item共现矩阵

2. 找到与用户x兴趣最相似的n个用户，可以使用余弦相似度、皮尔逊相关系数等方式进行相似度度量。使用皮尔逊相似度时可以使用用户平均分或商品平均分对用户评分进行修正，减少用户评分偏置或商品评分偏置对结果的影响（有些商品，用户本身评分比较高）

   ![](img/0006-1.png)

3. 综合考虑top n用户对物品y的评价：R(x,y) = sum(w(x, u) * R(u, y)) / sum(w(x, u))，u为topn相似用户。即对top n用户对物品y进行加权平均

   

缺点：

1. 在用户数远大于物品数的时候，用户相似度矩阵存储需要大量开销，以n^2的速度增长
2. 用户历史行为稀疏，不适合于那些获得正反馈困难的场景



### ItemCF

步骤与UserCF类似

1. 生成user-item共现矩阵
2. 根据用户的正反馈列表，计算相似度，找出top k最相似物品
3. 对相似集合中的物品，按如下方式计算相似度，R(x,y)=sum(w(p,y)R(x,p))，p为用户正反馈集合中的物品



### UserCF与ItemCF的应用场景

UserCF适合社交、新闻这样的场景，这些场景中新闻及时性、热点性、多样性比相关性更重要，ItemCF适合兴趣变化较为稳定的应用，如电商



### CF方法的缺点

CF无法将两个商品相似的信息推广到其他物品的计算上，导致头部效应明显（头部商品容易跟其他商品计算相似度），泛化能力弱。

   

### 矩阵分解-CF扩展

矩阵分解方法是协同过滤的发展，解决CF方法相似度计算无法推广到其他商品的问题

矩阵分解方法将nm的用户共现矩阵分解为nk的用户矩阵和km的物品矩阵，每个物品和用户用k维向量表示，这样任意一个物品都可以和任意一个用户进行相似度计算：r=u * p，及用户向量和物品向量做点积

#### 矩阵分解的求解方法

1. 特征值分解，只适用方阵，这里不适合

2. 奇异值分解，将矩阵分解为M=UEV，E为对角阵，取E中较大的k个值。要求原始矩阵是稠密的，而且分解复杂度高O(nmm)，不适合互联网海量数据场景

3. 梯度下降，直接学习用户和物品隐向量，优化目标是让用户真实评分与通过隐向量计算的评分尽可能接近

   ![](img/0006-2.png)

   在预估用户对物品打分的时候可以加一些偏置项，减小用户或物品打分的偏差

   ![](img/0006-3.png)

#### 矩阵分解方法的优缺点

优点：

1. 比协同过滤具有更强的泛化性
2. 不需要存用户相似性或物品相似性矩阵，空间复杂度低
3. 隐向量思想与深度学习embedding类似，可以与其他特征拼接，较为灵活

缺点：

1. 有局限，不能加入用户、物品和上下文相关特征

 

## 逻辑回归族

逻辑回归将推荐问题转化为点击率预估问题，可以综合考虑用户、物品、上下文特征，是深度学习模型的雏形

优点：

1. 是否点击服从伯努利分布，数学逻辑充分
2. 可解释强，可以得到每个特征的重要性程度
3. 训练和在线腿短高效

缺点：

1. 表达能力不强，无法进行特征交叉、筛选

## 因子分解机族

因子分解机方法可以解决逻辑回归不能够进行特征交叉问题

### POLY2

![](img/0006-4.png)

one-hot之后，对两两特征进行交叉

缺点：

1. 互联网数据



## 组合模型

